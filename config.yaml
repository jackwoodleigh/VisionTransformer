model:
  n_blocks: 8
  levels: 4
  dim: 60
  window_size: 8
  scale_factor: 4

training:
  learning_rate: 0.0001
  epochs: 2258
  batch_size: 2
  accumulation_steps: 8
  perceptual_loss_scale: 0.005
  fft_loss_scale: 0.01
  model_ema: 0.9975
  ema_start_epoch: 3
  data_subset: 0
  testing_data_split: 0.1
  image_height: 1080
  image_width: 1920
  transform_data: True

tools:
  log: True
  model_save_directory: "Model Saves"
  load_model_save_name: "model_save_epoch_133.pth"
  save_model_every_i_epoch: 1
  load_optimizer: True

