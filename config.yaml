model:
  n_blocks: 8
  levels: 4
  dim: 64
  features: 32
  window_size: 8
  scale_factor: 4

training:
  learning_rate: 0.001
  iterations: 500000
  epochs: 100
  batch_size: 32
  accumulation_steps: 2
  model_ema: 0.9995
  ema_start_epoch: 2
  criterion:
    CharbonnierLoss: 1
    FFTLoss: 0.025

data:
  data_subset: 0
  training_dataset_enlarge_scale: 10
  training_image_size: 256
  validation_image_size: 1080
  transform_data: True

tools:
  log: True
  save_path: "Model Saves"
  save_name: ""
  load_model_save_name: ""
  save_model_every_i_epoch: 1
  load_optimizer: False
  multi_gpu_enable: True

